**홀드아웃 기법**은 머신러닝 모델을 평가하고 일반화 성능을 확인하기 위한 가장 기본적인 검증 방법 중 하나입니다.

---

## ✅ 한 줄 정의

> **데이터셋을 훈련용(train)과 검증용(test)으로 나눠, 훈련과 평가를 따로 하는 방식**

---

## 🔍 왜 필요한가?

머신러닝 모델은 주어진 데이터를 학습해서 미래 데이터를 예측합니다.  
그런데 **훈련에 사용한 데이터로 테스트하면 성능을 속일 수 있어요**.  
→ 그래서 **아예 일부 데이터를 “떼어두고(hold out)”**,  
→ **그 데이터는 학습 없이 순수하게 평가용으로만 사용**하는 것이 핵심입니다.

---

## 🧱 데이터 분할 방식

보통 이렇게 나눕니다:

| 세트                 | 용도    | 비율(예시) |
| ------------------ | ----- | ------ |
| 훈련 데이터 (Train set) | 모델 학습 | 70~80% |
| 테스트 데이터 (Test set) | 모델 평가 | 20~30% |

🔹 추가로 **검증용(Validation set)**을 따로 둘 수도 있어요:

| 세트             | 용도         |
| -------------- | ---------- |
| **Train**      | 모델 학습      |
| **Validation** | 하이퍼파라미터 튜닝 |
| **Test**       | 최종 성능 평가   |

## ✅ 장점

- **간단하고 빠름**
- 초보자도 쉽게 사용 가능
- 대용량 데이터에서는 효과적임

## ❌ 단점

- 결과가 **데이터 분할에 민감**함  
    → 한 번의 테스트로 모델의 일반화 성능을 확신하기 어려움
- 작은 데이터셋에서는  
    → **테스트셋이 너무 적거나 훈련셋이 부족해질 수 있음**

> 그래서 보완책으로 **K-폴드 교차검증(K-fold cross-validation)**이 자주 함께 쓰입니다.

쓰레쉬홀드 값을 0.5로 고정하고 <- 0.5로 고정한 이유 발표준비할 때 다시 물어보기

addr_state 추가

- Sharpe ratio 공식 정의, 어떻게 접근했는지 (창재)
    - 공식 정의
    - IRR 어떻게 계산 - cashflow 설명›
    - weight 5가지 전략(노션 모델 구상 부분) 설명
    - 

$$ \text{Sharp} = \frac{\sum_{i=1}^{n} w_{i}(R_{i}-r_{f})}{\sqrt{\sum_{i=1}^{n} w_{i}(R_{i}-r_{f})^{2}}} =\frac{\sum_{i=1}^{n} w_{i}R_{i}-r_{f}}{\sqrt{\sum_{i=1}^{n} w_{i}R_{i}^{2}}} $$

$$ C_{t} = \text{t기 분할납부금}  $$

$$ \begin{eqnarray} 0 & = & -(\text{loan\_amnt})+\sum_{t=1}^{n}\frac{(\text{installment})}{(1+r)^{t}} \\ & = & - (\text{loan\_amnt}) + (\text{installment}) \frac{(1+r)^{n}-1}{(1+r)r} \end{eqnarray} $$