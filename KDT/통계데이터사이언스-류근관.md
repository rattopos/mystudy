# 통계, 데이터 사이언스 - 류근관

## 2025-07-03

IID: [Independent and identically distributed random variables - Wikipedia](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)
LLN: [Law of large numbers - Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)

[Explainable artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)

[Shapley value - Wikipedia](https://en.wikipedia.org/wiki/Shapley_value)

모든게 정규분포로 근사되는게 아니다.

현실의 정치적 견해가 정규분포와 다르게 쌍봉인 이유

중심극한 정리의 가정: 각각의 요인이 '독립'적으로 '엇비슷'하게 영향을 미쳐야 한다.

주식시장의 수익률: 정규분포보다 꼬리가 두껍다 (fat tail)

소득분포: right skewed distribution, mean: 1인당 GDP

q1 q2 q3를 보고 skewed인지 약간 판단 가능

베이즈 법칙

$$ P(A \mid B) = \frac{P(A)P(B\mid A)}{P(B)} $$

따라서

$$ \stackrel{\text{posterior}}{P(A \mid B)} \propto \stackrel{\text{prior}}{P(A)} \stackrel{\text{likelihood}}{P(B \mid A)} $$

likelihood, posterior, prior, marginal, joint

$$ P(A,B) = P(A) P(B \mid A) = P(B) P(A \mid B) $$

[Secretary problem - Wikipedia](https://en.wikipedia.org/wiki/Secretary_problem)

## 2025-07-07

${ \mu = ER }$로 두고 테일러 전개를 하면,

$$ E \log (1+R) \approx \mu-\frac{1}{2}\frac{\sigma^{2}}{(1+\mu)^{2}} $$

주식시장이 뉴스에 민감하게 반응 하는 이유 손절매(stop loss)를 프로그램으로 자동으로 걸어두기 때문에 연쇄반응 (fat tail을 설명)

[Bayesian updating](https://en.wikipedia.org/wiki/Bayesian_inference)

R passing stratege: 최고의 전략을 담은 class

H: 정보 엔트로피, MI: mutual information

$$ \operatorname{H}(X,Y) = \operatorname{H}(X) + \operatorname{H}(Y) - \mathrm{MI}(XY) $$

[Entropy (information theory) - Wikipedia](https://en.wikipedia.org/wiki/Entropy_\(information_theory\))
 
$$ \operatorname{H}(X) = \operatorname{E}_{X} \log_{2} \frac{1}{p(X)}  $$

${ \operatorname{MI}(X,Y) = }$ [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between ${ f(x,y) }$ and ${ f(x)f(y) }$

$$ p(X,Y) = \begin{dcases}
p(X) p(Y \mid X) \\
p(Y) p(X \mid Y)
\end{dcases} $$

$$ - \log_{2} p(X,Y) = \begin{dcases}
- \log_{2} p(X) - \log_{2} p(Y \mid X) \\
- \log_{2} p(Y) - \log_{2} p(X \mid Y)
\end{dcases}
$$

$$ \operatorname{H}(X,Y) = \operatorname{H}(X \mid Y) + \operatorname{H}(Y \mid X) + \operatorname{MI}(X,Y) $$

아들 잘 낳는 커플(B)이 아들 낳을 확률 0.6

딸 잘 낳는 커플이(G) 아들 낳을 확률 0.4

첫 아이가 아들일 때 둘째도 아들일 확률?

B: ${ 0.6 \times 0.6 = 0.36 }$
G: ${ 0.4 \times 0.4 = 0.16 }$
B와 G가 독립이므로 ${ 0.52 }$
따라서 ${ 0.6 }$과 0.4의 평균인 ${ 0.5 }$ 보다 크다.

IID 보다 [Exchangeablity](https://en.wikipedia.org/wiki/Exchangeable_random_variables)가 현실을 더 잘 설명한다. (확률분포가 치우쳐져 있다)

콜옵션

treasury bond: $1 → (1+r)
stock: $1 → 1+u, 1-u
call option (X = exercise price)
$c → ${ (1+u) - X }$, ${ \max((1-u)-X,0)=0 }$

[Law of one price - Wikipedia](https://en.wikipedia.org/wiki/Law_of_one_price)

[Risk-neutral measure - Wikipedia](https://en.wikipedia.org/wiki/Risk-neutral_measure)

[제곱근의 법칙](https://www.britannica.com/science/probability-theory/The-central-limit-theorem#ref407420)
교재 250p.
$$ \text{(합의 표준오차)} = \text{(상자의 표준편차)}\times \sqrt{\text{추출 횟수}} $$
추출횟수가 100배면 표준오차는 10배
통계가 엉망인 예: "남자로 한정하면~" 표본이 줄어드므로 오차한계가 낮아진다.

학교에서는 hypothesis test만 가르치는데 현실은 model selection
cannot reject는 어쩔껀데? 정말 무의미하다.(생산적이지 않음, 게르다는 것을 시인하는 것) 빅데이터 시대에 표본의 수가 무한대로 가면 모든 T-테스트가 리젝된다.

model 하나 세워두고 테스트 통과했다: nonsense... 게으른 것. 제일 적합한 model을 골라야함.

[All models are wrong - Wikipedia](https://en.wikipedia.org/wiki/All_models_are_wrong)

[Ensemble learning - Wikipedia](https://en.wikipedia.org/wiki/Ensemble_learning)

accuracy에 집착하는 것은 잘못되었다. 그런건 희귀병에나 의미 있다.

대수의 법칙
1. big mouth가 없어야 한다
2. doubling strategy엔 먹히지 않음

한 종목에 올인한다 = 완전히 같이 움직이는 두 종목에 1/2, 1/2 상관계수 +1

두 종목인데 상관계수가 0.99면 다변효과가 있다?

R1, R2 indep.
${ \text{Corr}(R_{1},R_{2}) = \rho }$

$$ \begin{eqnarray} Var(R) & = & E(R - ER)^{2} \\
& = & E(0.5(R_{1}-ER_{1}) + 0.5(R_{2}-ER_{2})) \\ 
& = & \frac{1}{4} \sigma_{1}^{2} + \frac{1}{4}\sigma_{2}^{2} + \frac{1}{2}\rho \sigma_{1} \sigma_{2} \\
& \stackrel{\sigma_{1}^{2}=\sigma_{2}^{2}}{=} & \frac{\sigma^{2}}{2} (1+\rho) \stackrel{-1 \le \rho \le 1}{\le} \sigma^{2}
\end{eqnarray} $$

$$ \sigma_{R} = \sqrt{\frac{1+\rho}{2}}\sigma $$

special cases
1. ${ \rho = +1 \implies \sigma_{R} = \sigma }$
2. ${ \rho = -1 \implies \sigma_{R}=0 }$
3. ${ \rho = 0 \implies \sigma_{R} = \frac{\sigma}{\sqrt{2} } }$
In general (${ \rho \neq \pm 1 ) }$, ${ \sigma_{R}<\sigma }$

[Law of total expectation - Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_expectation)

[Law of total variance - Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_variance)

## 2025-07-10

스스로 해보기: [binomial model of stock prices](https://en.wikipedia.org/wiki/Risk-neutral_measure#Example_1_%E2%80%93_Binomial_model_of_stock_prices); [Black–Scholes model - Wikipedia](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model)로 수렴하는 것도 알 수 있음.

부트스트랩 방법에 헷갈리는게 있는데 그거 반드시 생각해보기

어떤 분포를 정규분포로 가정하는 가정할 필요가 없어졌다. 컴퓨터가 많이 발달했기 때문에 sampling with replacement로 하는 시뮬레이션이 더 정확하다.

KL - divergence

$$ KL(p \parallel q) = E_{p}(\log p - \log q) = \stackrel{\text{cross entropy}}{(-E_{p} \log q)} - (\stackrel{\text{own entropy}}{-E_{p} \log p})$$
|              | 좋은 코딩   | 나쁜 코딩         |
| ------------ | ------- | ------------- |
| sunny, 0.5   | 1, 0.5  | 01, 1, 0.25   |
| rainy, 0.25  | 01, 0.5 | 1, 0.25, 0.5  |
| cloudy, 0.25 | 00, 0.5 | 00, 0.5, 0.25 |
| 평균 비트        | 1.5     | 1.75          |
거꾸로 ${ \log_{2} \frac{1}{q}  }$로 원래 확률분포를 유추할 수 있다.

$$ -KL(p \parallel q) = E_{p}(\log \frac{q}{p}) \stackrel{\text{Jensen}}{\le} \log(E_{p}\frac{q}{p}) $$

등호는 q/p가 상수일때, 즉 q/p=1

Deep Learning: KL-divergence의 값을 minimize 하는 방법으로 training (원래 분포와 가깝게?)
${ p }$를 ${ \hat{p} }$으로 근사 (empirical distribution)

최후추정법(사진 참고) MLE

distance가 아니라 divergence라고 부르는 이유
p와 q에 대칭성이 없어서.
상황에 따라서 q를 기준으로 재는 경우도 있음 더 편리한 쪽을 선택.

위 코드예시에서 KL(p||q) 와 KL(q||p) 계산해보기 (똑같이 나옴)

스스로 해보기: 다르게 나오는 예시 만들어보기

review

| name           | inequality                                                            |
| -------------- | --------------------------------------------------------------------- |
| Markov         | ${ P(Y \ge c) \le \frac{E(Y)}{c} }$                                   |
| Chebyshev      | ${ P(\left\lvert Y-EY \right\rvert \ge k\sigma) \le \frac{1}{k^{2}}}$ |
| Cauchy-Schwarz | ${ E(X^{2}) E(Y^{2}) \ge E(X)^{2}E(Y)^{2} }$                          |

SK증권 JP모건
선수끼리 거래하는데 위험은 스스로 판단해야지...

앞으로 1년과 과거 1년이 같다고 모델을 세운다. (같을리가 없지만 실용적인 이유로)

financial bootstraping

강남아파트 가격 선형회귀 실제로 계산해보기

[Omitted-variable bias - Wikipedia](https://en.wikipedia.org/wiki/Omitted-variable_bias): 현실에서 너무 너무 많다

[Bias (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Bias_(statistics))

aggregation bias

regression effect

regression의 유래: 갈튼의 키 연구

$$ \left\lvert b \right\rvert \le \frac{SD_{Y}}{SD_{X}} $$

스포츠 기자들이 루키보고 슬럼프라고 오판

경제학자들이 GDP 회귀분석 하는데 수렴할거라고 오판

회귀분석의 기울기가 시간이 갈 수록 0으로 가는 이유의 올바른 해석은 Y의 차이를 더 이상 X의 차이로 설명할게 없어진다는 것이다. Y의 차이가 없다가 아님.

스스로 해보기
- [x] binomial of stock price
- [x] KL-divergence 비대칭인거 찾아보기
- [ ] 확률론 부등식 증명
- [ ] 부트스트랩핑 헷갈리는거 잘 생각해보기
- [x] financial bootstraping 찾아보기
- [x] 전미분이 왜 전미분인지 생각해보기
- [ ] 강남아파트 가격 데이터 받아서 파이썬으로 선형회귀 실제로 계산해보기
- [ ] 강남아파트 가격을 통해서 왜 변수 통제가 중요한지 생각해보기 (omitted-variable bias) 프로젝션 이리저리 해보기.
- [ ] 몬테카를로 방법 오차의 한계 생각해보기 (오늘배운 내용 (아마 제곱근의 법칙?)과 연관해서 생각해보기

## 2025-07-14

[Confounding - Wikipedia](https://en.wikipedia.org/wiki/Confounding)

accuracy maximize 보단 objective oriented inference

### 🎓 류근관 교수님의 맥락에서 "Objective-Oriented Inference"란?

다음과 같은 아이디어에 기반하고 있습니다:

#### ✅ **목적 지향 추론 vs. 진리 지향 추론**

- **진리 지향적 추론 (Truth-oriented inference)**:  
    → "모수(parameter)의 진짜 값을 얼마나 정확히 추정하느냐"에 초점  
    → 전통적인 통계학(예: Neyman-Pearson, classical estimation)
    
- **목적 지향적 추론 (Objective-oriented inference)**:  
    → "그 추정이 실제 의사결정이나 정책 목표에 어떤 영향을 주느냐"에 초점  
    → 추정의 **정확성**보다 **유용성/효용성**이 중요  
    → 예: 잘못된 추정이더라도, 정책결정에 도움이 된다면 그게 더 중요한 것
    

---

### 📌 예시 (경제학·정책 분석 관점에서)

- 어떤 교육정책이 학생의 성적에 영향을 미치는지를 분석할 때:
    
    - **진리 지향적 추론**: 정책의 효과를 엄밀히 추정하는 데 초점.
        
    - **목적 지향적 추론**: 정책이 실제로 성과를 개선하게 유도하는 방향으로 추론하는 것에 초점.
        
- 의료비 데이터를 분석할 때:
    
    - 진리 지향: 평균 의료비 정확히 추정.
        
    - 목적 지향: 그 추정값이 보험료 책정이나 정책 설계에 잘 작동하느냐가 더 중요.
        

---

### 📘 류 교수님의 교재나 강의 슬라이드에선 주로 다음처럼 요약됩니다:

> “우리는 단지 parameter 값을 정확히 추정하는 데 관심이 있는 것이 아니라,  
> 그 추정이 의사결정에 어떤 도움을 주는지에 관심이 있다.”

이 관점은 **통계학이 실천적 의사결정 도구로서 기능해야 한다**는 실용주의적 철학에 기반한 것이고, 특히 **정책학, 계량경제학, 사회과학** 쪽에서 매우 중요하게 다뤄집니다.

---

### 🔁 요약

|구분|설명|
|---|---|
|**Truth-oriented**|parameter 값을 정확히 추정하려는 전통적 통계 접근|
|**Objective-oriented**|실용적·정책적 목적에 맞는 유용한 추론을 강조|

[Hedonic regression - Wikipedia](https://en.wikipedia.org/wiki/Hedonic_regression)

데이터를 무작정 많이 넣는다고 좋은게 아니다, 통제된 데이터를 넣지 않으면 통계를 왜곡하게 된다.

[노벨상이 밝힌 남녀 임금격차의 진실](https://brunch.co.kr/@brazilclub/132)

linear spline regression도 중회귀 분석:
계수 ${ \beta_{1},\beta_{2} }$ 두 개로 2차원 평면을 만들기 때문인가?

도메인 지식이 없는 상태로 데이터 분석을 하는 것만큼 위험한게 없다.

조정된 결정계수: 자유도로 나눠줘서 설명변수가 정말로 제대로 역할을 하는지 판단할 수 있다. <- 지금은 잘 안 씀

KNN: 한 사람을 알려면, 그 사람의 친구를 보라.
birds of a feather flock together, 유유상종

${ y = f(x) + \varepsilon }$

$$ y - \hat{f}(x) = \overbrace{y - E(y \mid x)}^{A} + \overbrace{E(y\mid x) - f(x)}^{B} + \overbrace{f(x) - \hat{f}(x)}^{C} $$

Want ${ E[y\mid x] }$

- A: 에라 모르겠다
- B: estimation error
- C: sampling error


$$ \text{MSE} := E\left(\left( f(x) - \hat{f}(x)\right) \right) = \sigma^{2} + \mathrm{Bias}^{2} + \mathrm{Var}^{2} $$

- ${ \sigma^{2} = E(A^{2}) }$
- ${ \mathrm{Bias}^{2} = E(B^{2}) }$
- ${ \mathrm{Var}^{2} = E(C^{2}) }$

- [ ] A,B,C 쌍마다 correlation이 0인거 생각해보기

패널티를 주는 세기에 따라 모델이 결정된다. 

[Hyperparameter (Bayesian statistics) - Wikipedia](https://en.wikipedia.org/wiki/Hyperparameter_(Bayesian_statistics))

[Additive smoothing - Wikipedia](https://en.wikipedia.org/wiki/Additive_smoothing)

[Perron–Frobenius theorem - Wikipedia](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem)

[Shrinkage (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Shrinkage_(statistics))

[out-of-sample error](https://en.wikipedia.org/wiki/Generalization_error)

## 2025-07-21

$$ y_{i} = x_{i}' \beta + \varepsilon_{i} $$

$$ \underbracket{y}_{n \times 1} = \underbracket{X}_{n \times k} \underbracket{\beta}_{k \times 1} + \underbracket{\varepsilon}_{n \times 1} $$

[Ridge regression - Wikipedia](https://en.wikipedia.org/wiki/Ridge_regression)

[Lasso (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Lasso_\(statistics\)): 뚱뚱한 데이터에서 많이 쓴다(=케이스에 비해 데이터가 많은것). 많지 않은 케이스 가지고 대표를 뽑는 경우 유용하다.

> accuracy-simplicity tradeoff 가지고 regulation을 직관화할 수 있나? - 나

통계학은 기계적으로 수식에 대입하는게 아니라 데이터를 어떻게 다룰 것인지 이해해야 한다.

test에서 중요한 것은 test는 별로 중요하지 않고 생산적이지 않다는 것. 빅데이터 시대에는 reject 안되면 그게 기적이다.

runs test: 하나의 run은 같은 부호의 연속
run이 많다: mean reversion
positive correlation = momentum이 있으면 run이 줄어든다.

귀무가설: momentum이 존재하지 않는다.
대립가설: momentum이 존재한다.

+6, -4로 이루어진 무

가설검정: 좋다 니말이 맞다 치자

[Model selection - Wikipedia](https://en.wikipedia.org/wiki/Model_selection)

[Regularization (mathematics) - Wikipedia](https://en.wikipedia.org/wiki/Regularization_\(mathematics\))

[Z-test - Wikipedia](https://en.wikipedia.org/wiki/Z-test)

[Student's t-test - Wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-test)

[p-value - Wikipedia](https://en.wikipedia.org/wiki/P-value)

[Sign test - Wikipedia](https://en.wikipedia.org/wiki/Sign_test)

[Chi-squared test - Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_test): 주사위가 균형잡혔냐?

[통계데이터센터](https://data.kostat.go.kr/sbchome/index.do): 사업을 할 때 이용해보라

모든 유권자보단 투표할 것 같은 유권자가 더 적합하다. screening question으로 어느정도 알아낼 수 있음. 표본이 단순히 많다고 좋은 것이 아니다.

응답편의: 조사하는 사람을 실망시키지 않으려고 속마음을 감출 수도 있다.

[Dummy variable (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Dummy_variable_\(statistics\))

$$ y_{it} = \alpha + \gamma d_{i}+ \varepsilon_{it} $$

$$ i= \begin{dcases}
1 & \text{if } i \in \mathrm{BG} \\
0 & \text{otherwise}
\end{dcases} $$

$$ \gamma = \gamma_{0} + \gamma_{1}d_{t1} + \cdots + \gamma_{m}d_{tm} $$

where $$ d_{tj} = \begin{dcases}
1 & \text{if } t=j \\
0 & \text{otherwise}
\end{dcases} $$
시기별로 분석하면 기존학자들이 분석한것과 정반대

[Error function - Wikipedia](https://en.wikipedia.org/wiki/Error_function)

왜 표준편차가 아니라 표준표차인가? 어떤 표준오차를 쓰는지가 더 좋은 질문이다.

답: 당신이 쓰는 통계량의 표준오차.

- [ ] runs test 표 만들어보기
- [ ] t-값과 빅데이터의 관계를 생각해보기

조별 프로젝트는 accuracy가 아니라 [Sharpe ratio](https://en.wikipedia.org/wiki/Sharpe_ratio) 극대화

8월 7일 조별 프로젝트 발표. 발표시간 20분 지나면 칼 같이 자를 것이다. 수식 들이밀고 수식만 설명하는 것보단 의미 위주로 설명.

[Implied volatility - Wikipedia](https://en.wikipedia.org/wiki/Implied_volatility)

## 2025-07-23

shaply value가 인과관계를 말해주진 않음. 중국 지역별 성장속도 차이는 외국자본 덕분인가? 애초에 외국 자본은 성장 가능성이 높은 곳에 모인다.

현실에서는 가설 검정은 별로 유용하지 않고 out-of-sample을 많은 반복을 통해 constant를 정한다. roburstness check.

가장 좋은 능력은 좋은 문제를 출제하는 능력 (슘페터: 혁신)

[Joseph Schumpeter - Wikipedia](https://en.wikipedia.org/wiki/Joseph_Schumpeter)

[k-anonymity - Wikipedia](https://en.wikipedia.org/wiki/K-anonymity)

[k-nearest neighbors algorithm - Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)

- [ ] k가 변할 때 무엇이 어떻게 trade-off 되는지 알아보기 

supervised learning: regression, indifference curve 등등

[Self-supervised learning - Wikipedia](https://en.wikipedia.org/wiki/Self-supervised_learning): next word prediction

[Reinforcement learning - Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning)

[Hallucination (artificial intelligence) - Wikipedia](https://en.wikipedia.org/wiki/Hallucination_\(artificial_intelligence\)) = dynamic forecast?

[k-means clustering - Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering)

[Dendrogram - Wikipedia](https://en.wikipedia.org/wiki/Dendrogram)

클러스터 사이에 거리를 재야 한다.

Q. 무엇이 좋은 거리냐? (두 집단을 합칠 때 예시)
1. 평균점과 평균점 사이의 거리 (두 집단의 사람들이 평균적으로 잘 어울리는지?)
2. 두 클러스터 점 사이 거리들의 평균
3. 거리들의 최소값 (한명이라도 가까운 사람이 있으면 그 사람 통해서 다 친해짐)
4. 거리들의 최대값 (한명이라도 사이가 안 좋으면 분위기 썰렁)

빅데이터가 정보격차를 없애서 경제학적으로 놀라운 일을 가능하게 했다.
: 카셰어링, 에어비앤비, 레몬 마켓 등 플랫폼에서 위험을 필터링해서 가능.

deep learning은 중간에 반드시 비선형변환을 해야된다 안하면 선형변환 하나로 무너짐

[Backpropagation - Wikipedia](https://en.wikipedia.org/wiki/Backpropagation)

[Isoquant curve](https://en.wikipedia.org/wiki/Isoquant) v.s. [Indifference curve](https://en.wikipedia.org/wiki/Indifference_curve)

## 2025-07-28

Today

Tree
- c.f. variance decomposition formula: within v.s. between
- bootstrapping ${ \implies }$ "a frest than a tree"
- sampling o featuress ${ \implies }$ decorrelation among trees
XIA and Shapley
information theory

[Law of total variance - Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_variance)

$$ \operatorname{Var}(Y) = \operatorname{E}\operatorname{Var}(Y \mid X) + \operatorname{Var}(\operatorname{E}(Y \mid X)) $$

total var = within, undexplained var + between, explaind var

특정 데이터가 bootstraping에 포함되지 않을 확률

n = sample  size

$$ (1-\frac{1}{n})^{n} \rightarrow e^{-1} = 0.367879 \dots $$

Suppose ${ Y_{1},Y_{2} \sim (\mu,\sigma^{2}) }$

$$ \operatorname{Var}(\overline{Y}) = \frac{\sigma^{2}+\sigma^{2}+2\rho\sigma}{4}=\frac{\sigma^{2}}{2}(1+\rho) $$

where ${ \overline{Y} = \frac{Y_{1}+Y_{2}}{2} }$ and ${ \rho = \operatorname{Corr(Y_{1}, Y_{2}}) }$

boosting은 replication이 아니다 (앙상블과 관련 없다) <- 많이들 혼동해서 쓴다.

Madison이 쓴거냐 Hamilton

[Naive Bayes classifier - Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier): 실제로는 독립이 아니지만 실용적으로 독립이라 가정(naive한 가정)하고 베이즈 법칙을 적용

$$ \frac{P(M_{1}\mid T_{1},\dots,T_{m})}{P(M_{2}\mid T_{1},\dots,T_{m})} = \frac{P(M_{1})}{P(M_{2})} \frac{P(T_{1}, \dots,T_{m} \mid M_{1})}{P(T_{1},\dots,T_{m} \mid M_{2})}$$

posterior odds ratio = prior odds ratio ${ \times }$ likelihood ratio

$$ y = f(x_{1},\dots,x_{k}) + \varepsilon $$

1. prediction
2. explaining the predictive outcom, XAI, Shapley
3. causal inference

cooperative game에서 유일한 value

[Marginal value - Wikipedia](https://en.wikipedia.org/wiki/Marginal_value)

세 당의 의석이 40% 40% 11%인데 지분은 1/3 1/3 1/3으로 동일

[Heat map - Wikipedia](https://en.wikipedia.org/wiki/Heat_map)

shapely value는 공장을 모니터링 하는 것에서도 사용할 수 있다.

## 2025-07-29

${ p }$: "empirical" real probability
${ q }$: "counter-factural" probability, hypothetical

$$ H = E_{p}\log_{2}(\frac{1}{p}),\ \mathrm{CE} = E_{p}\log_{2}(\frac{1}{q}) $$

${ \mathrm{KL} = \mathrm{CE} - H }$

$$ \mathrm{KL} = - E_{p} \log_{2}(\frac{q}{p}) \ge - \log_{2}E_{p}(\frac{q}{p}) =0$$

등호는 ${ p = q }$ 만 성립 ${ \implies }$KL divegence를 최소화 하는 것은 진실에 가까이 가는 것.

$$ \min_{q} \mathrm{CE} \iff \min_{q} \mathrm{KL} $$

$$ \begin{eqnarray}
\min_{q} \mathrm{CE} & = & \min_{q} -E_{p}\log_{2} q \\
& \approx & \min_{q} -\hat{E}\log_{2}q \\
& = & \min_{q} -\frac{1}{n} \sum_{i=1}^{n} \log_{2} q_{i} \\
& \iff & \underbracket{\max_{q} \log_{2}L}_{\text{최우 추정법}}
\end{eqnarray} $$

[Maximum likelihood estimation - Wikipedia](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)

${ Y_{-} }$: own history of ${ Y }$
${ X_{-} }$: cross history

$$ H(Y \mid Y_{-}) \ge H(Y \mid Y_{-},X_{-}) $$

TE: transfer entropy

$$ \mathrm{TE} = H(Y \mid Y_{-}) -H(Y \mid Y_{-},X_{-})  $$

[Transfer entropy - Wikipedia](https://en.wikipedia.org/wiki/Transfer_entropy)

주식시장에 대입하여 이해해보기.

[Autoregressive model - Wikipedia](https://en.wikipedia.org/wiki/Autoregressive_model)

[Granger causality - Wikipedia](https://en.wikipedia.org/wiki/Granger_causality): transfer entropy의 일종

[Cholesky decomposition - Wikipedia](https://en.wikipedia.org/wiki/Cholesky_decomposition)

[[ML] Precision 과 Recall의 Trade-off, 그리고 ROC Curve](https://techblog-history-younghunjo1.tistory.com/101)