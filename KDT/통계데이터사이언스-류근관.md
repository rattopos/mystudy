# 통계, 데이터 사이언스 - 류근관

## 2025-07-03

IID: [Independent and identically distributed random variables - Wikipedia](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)
LLN: [Law of large numbers - Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)

[Explainable artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)

[Shapley value - Wikipedia](https://en.wikipedia.org/wiki/Shapley_value)

모든게 정규분포로 근사되는게 아니다.

현실의 정치적 견해가 정규분포와 다르게 쌍봉인 이유

중심극한 정리의 가정: 각각의 요인이 '독립'적으로 '엇비슷'하게 영향을 미쳐야 한다.

주식시장의 수익률: 정규분포보다 꼬리가 두껍다 (fat tail)

소득분포: right skewed distribution, mean: 1인당 GDP

q1 q2 q3를 보고 skewed인지 약간 판단 가능

베이즈 법칙

$$ P(A \mid B) = \frac{P(A)P(B\mid A)}{P(B)} $$

따라서

$$ \stackrel{\text{posterior}}{P(A \mid B)} \propto \stackrel{\text{prior}}{P(A)} \stackrel{\text{likelihood}}{P(B \mid A)} $$

likelihood, posterior, prior, marginal, joint

$$ P(A,B) = P(A) P(B \mid A) = P(B) P(A \mid B) $$

[Secretary problem - Wikipedia](https://en.wikipedia.org/wiki/Secretary_problem)

## 2025-07-07

${ \mu = ER }$로 두고 테일러 전개를 하면,

$$ E \log (1+R) \approx \mu-\frac{1}{2}\frac{\sigma^{2}}{(1+\mu)^{2}} $$

주식시장이 뉴스에 민감하게 반응 하는 이유 손절매(stop loss)를 프로그램으로 자동으로 걸어두기 때문에 연쇄반응 (fat tail을 설명)

[Bayesian updating](https://en.wikipedia.org/wiki/Bayesian_inference)

R passing stratege: 최고의 전략을 담은 class

H: 정보 엔트로피, MI: mutual information

$$ \operatorname{H}(X,Y) = \operatorname{H}(X) + \operatorname{H}(Y) - \mathrm{MI}(XY) $$

[Entropy (information theory) - Wikipedia](https://en.wikipedia.org/wiki/Entropy_\(information_theory\))
 
$$ \operatorname{H}(X) = \operatorname{E}_{X} \log_{2} \frac{1}{p(X)}  $$

${ \operatorname{MI}(X,Y) = }$ [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between ${ f(x,y) }$ and ${ f(x)f(y) }$

$$ p(X,Y) = \begin{dcases}
p(X) p(Y \mid X) \\
p(Y) p(X \mid Y)
\end{dcases} $$

$$ - \log_{2} p(X,Y) = \begin{dcases}
- \log_{2} p(X) - \log_{2} p(Y \mid X) \\
- \log_{2} p(Y) - \log_{2} p(X \mid Y)
\end{dcases}
$$

$$ \operatorname{H}(X,Y) = \operatorname{H}(X \mid Y) + \operatorname{H}(Y \mid X) + \operatorname{MI}(X,Y) $$

아들 잘 낳는 커플(B)이 아들 낳을 확률 0.6

딸 잘 낳는 커플이(G) 아들 낳을 확률 0.4

첫 아이가 아들일 때 둘째도 아들일 확률?

B: ${ 0.6 \times 0.6 = 0.36 }$
G: ${ 0.4 \times 0.4 = 0.16 }$
B와 G가 독립이므로 ${ 0.52 }$
따라서 ${ 0.6 }$과 0.4의 평균인 ${ 0.5 }$ 보다 크다.

IID 보다 [Exchangeablity](https://en.wikipedia.org/wiki/Exchangeable_random_variables)가 현실을 더 잘 설명한다. (확률분포가 치우쳐져 있다)

콜옵션

treasury bond: $1 → (1+r)
stock: $1 → 1+u, 1-u
call option (X = exercise price)
$c → ${ (1+u) - X }$, ${ \max((1-u)-X,0)=0 }$

[Law of one price - Wikipedia](https://en.wikipedia.org/wiki/Law_of_one_price)

[Risk-neutral measure - Wikipedia](https://en.wikipedia.org/wiki/Risk-neutral_measure)

[제곱근의 법칙](https://www.britannica.com/science/probability-theory/The-central-limit-theorem#ref407420)
교재 250p.
$$ \text{(합의 표준오차)} = \text{(상자의 표준편차)}\times \sqrt{\text{추출 횟수}} $$
추출횟수가 100배면 표준오차는 10배
통계가 엉망인 예: "남자로 한정하면~" 표본이 줄어드므로 오차한계가 낮아진다.

학교에서는 hypothesis test만 가르치는데 현실은 model selection
cannot reject는 어쩔껀데? 정말 무의미하다.(생산적이지 않음, 게르다는 것을 시인하는 것) 빅데이터 시대에 표본의 수가 무한대로 가면 모든 T-테스트가 리젝된다.

model 하나 세워두고 테스트 통과했다: nonsense... 게으른 것. 제일 적합한 model을 골라야함.

[All models are wrong - Wikipedia](https://en.wikipedia.org/wiki/All_models_are_wrong)

[Ensemble learning - Wikipedia](https://en.wikipedia.org/wiki/Ensemble_learning)

accuracy에 집착하는 것은 잘못되었다. 그런건 희귀병에나 의미 있다.

대수의 법칙
1. big mouth가 없어야 한다
2. doubling strategy엔 먹히지 않음

한 종목에 올인한다 = 완전히 같이 움직이는 두 종목에 1/2, 1/2 상관계수 +1

두 종목인데 상관계수가 0.99면 다변효과가 있다?

R1, R2 indep.
${ \text{Corr}(R_{1},R_{2}) = \rho }$

$$ \begin{eqnarray} Var(R) & = & E(R - ER)^{2} \\
& = & E(0.5(R_{1}-ER_{1}) + 0.5(R_{2}-ER_{2})) \\ 
& = & \frac{1}{4} \sigma_{1}^{2} + \frac{1}{4}\sigma_{2}^{2} + \frac{1}{2}\rho \sigma_{1} \sigma_{2} \\
& \stackrel{\sigma_{1}^{2}=\sigma_{2}^{2}}{=} & \frac{\sigma^{2}}{2} (1+\rho) \stackrel{-1 \le \rho \le 1}{\le} \sigma^{2}
\end{eqnarray} $$

$$ \sigma_{R} = \sqrt{\frac{1+\rho}{2}}\sigma $$

special cases
1. ${ \rho = +1 \implies \sigma_{R} = \sigma }$
2. ${ \rho = -1 \implies \sigma_{R}=0 }$
3. ${ \rho = 0 \implies \sigma_{R} = \frac{\sigma}{\sqrt{2} } }$
In general (${ \rho \neq \pm 1 ) }$, ${ \sigma_{R}<\sigma }$

[Law of total expectation - Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_expectation)

[Law of total variance - Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_variance)

## 2025-07-10

스스로 해보기: [binomial model of stock prices](https://en.wikipedia.org/wiki/Risk-neutral_measure#Example_1_%E2%80%93_Binomial_model_of_stock_prices); [Black–Scholes model - Wikipedia](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model)로 수렴하는 것도 알 수 있음.

부트스트랩 방법에 헷갈리는게 있는데 그거 반드시 생각해보기

어떤 분포를 정규분포로 가정하는 가정할 필요가 없어졌다. 컴퓨터가 많이 발달했기 때문에 sampling with replacement로 하는 시뮬레이션이 더 정확하다.

KL - divergence

$$ KL(p \parallel q) = E_{p}(\log p - \log q) = \stackrel{\text{cross entropy}}{(-E_{p} \log q)} - (\stackrel{\text{own entropy}}{-E_{p} \log p})$$
|              | 좋은 코딩   | 나쁜 코딩         |
| ------------ | ------- | ------------- |
| sunny, 0.5   | 1, 0.5  | 01, 1, 0.25   |
| rainy, 0.25  | 01, 0.5 | 1, 0.25, 0.5  |
| cloudy, 0.25 | 00, 0.5 | 00, 0.5, 0.25 |
| 평균 비트        | 1.5     | 1.75          |
거꾸로 ${ \log_{2} \frac{1}{q}  }$로 원래 확률분포를 유추할 수 있다.

$$ -KL(p \parallel q) = E_{p}(\log \frac{q}{p}) \stackrel{\text{Jensen}}{\le} \log(E_{p}\frac{q}{p}) $$

등호는 q/p가 상수일때, 즉 q/p=1

Deep Learning: KL-divergence의 값을 minimize 하는 방법으로 training (원래 분포와 가깝게?)
${ p }$를 ${ \hat{p} }$으로 근사 (empirical distribution)

최후추정법(사진 참고) MLE

distance가 아니라 divergence라고 부르는 이유
p와 q에 대칭성이 없어서.
상황에 따라서 q를 기준으로 재는 경우도 있음 더 편리한 쪽을 선택.

위 코드예시에서 KL(p||q) 와 KL(q||p) 계산해보기 (똑같이 나옴)

스스로 해보기: 다르게 나오는 예시 만들어보기

review

| name           | inequality                                                            |
| -------------- | --------------------------------------------------------------------- |
| Markov         | ${ P(Y \ge c) \le \frac{E(Y)}{c} }$                                   |
| Chebyshev      | ${ P(\left\lvert Y-EY \right\rvert \ge k\sigma) \le \frac{1}{k^{2}}}$ |
| Cauchy-Schwarz | ${ E(X^{2}) E(Y^{2}) \ge E(X)^{2}E(Y)^{2} }$                          |

SK증권 JP모건
선수끼리 거래하는데 위험은 스스로 판단해야지...

앞으로 1년과 과거 1년이 같다고 모델을 세운다. (같을리가 없지만 실용적인 이유로)

financial bootstraping

강남아파트 가격 선형회귀 실제로 계산해보기

[Omitted-variable bias - Wikipedia](https://en.wikipedia.org/wiki/Omitted-variable_bias): 현실에서 너무 너무 많다

[Bias (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Bias_(statistics))

aggregation bias

regression effect

regression의 유래: 갈튼의 키 연구

$$ \left\lvert b \right\rvert \le \frac{SD_{Y}}{SD_{X}} $$

스포츠 기자들이 루키보고 슬럼프라고 오판

경제학자들이 GDP 회귀분석 하는데 수렴할거라고 오판

회귀분석의 기울기가 시간이 갈 수록 0으로 가는 이유의 올바른 해석은 Y의 차이를 더 이상 X의 차이로 설명할게 없어진다는 것이다. Y의 차이가 없다가 아님.

스스로 해보기
- [ ] binomial of stock price
- [ ] KL-divergence 비대칭인거 찾아보기
- [ ] 확률론 부등식 증명
- [ ] 부트스트랩핑 헷갈리는거 잘 생각해보기
- [ ] financial bootstraping 찾아보기
- [ ] 전미분이 왜 전미분인지 생각해보기
- [ ] 강남아파트 가격 데이터 받아서 파이썬으로 선형회귀 실제로 계산해보기
- [ ] 강남아파트 가격을 통해서 왜 변수 통제가 중요한지 생각해보기 (omitted-variable bias) 프로젝션 이리저리 해보기.
- [ ] 몬테카를로 방법 오차의 한계 생각해보기 (오늘배운 내용 (아마 제곱근의 법칙?)과 연관해서 생각해보기

## 2025-07-14

[Confounding - Wikipedia](https://en.wikipedia.org/wiki/Confounding)

accuracy maximize 보단 objective oriented inference

### 🎓 류근관 교수님의 맥락에서 "Objective-Oriented Inference"란?

다음과 같은 아이디어에 기반하고 있습니다:

#### ✅ **목적 지향 추론 vs. 진리 지향 추론**

- **진리 지향적 추론 (Truth-oriented inference)**:  
    → "모수(parameter)의 진짜 값을 얼마나 정확히 추정하느냐"에 초점  
    → 전통적인 통계학(예: Neyman-Pearson, classical estimation)
    
- **목적 지향적 추론 (Objective-oriented inference)**:  
    → "그 추정이 실제 의사결정이나 정책 목표에 어떤 영향을 주느냐"에 초점  
    → 추정의 **정확성**보다 **유용성/효용성**이 중요  
    → 예: 잘못된 추정이더라도, 정책결정에 도움이 된다면 그게 더 중요한 것
    

---

### 📌 예시 (경제학·정책 분석 관점에서)

- 어떤 교육정책이 학생의 성적에 영향을 미치는지를 분석할 때:
    
    - **진리 지향적 추론**: 정책의 효과를 엄밀히 추정하는 데 초점.
        
    - **목적 지향적 추론**: 정책이 실제로 성과를 개선하게 유도하는 방향으로 추론하는 것에 초점.
        
- 의료비 데이터를 분석할 때:
    
    - 진리 지향: 평균 의료비 정확히 추정.
        
    - 목적 지향: 그 추정값이 보험료 책정이나 정책 설계에 잘 작동하느냐가 더 중요.
        

---

### 📘 류 교수님의 교재나 강의 슬라이드에선 주로 다음처럼 요약됩니다:

> “우리는 단지 parameter 값을 정확히 추정하는 데 관심이 있는 것이 아니라,  
> 그 추정이 의사결정에 어떤 도움을 주는지에 관심이 있다.”

이 관점은 **통계학이 실천적 의사결정 도구로서 기능해야 한다**는 실용주의적 철학에 기반한 것이고, 특히 **정책학, 계량경제학, 사회과학** 쪽에서 매우 중요하게 다뤄집니다.

---

### 🔁 요약

|구분|설명|
|---|---|
|**Truth-oriented**|parameter 값을 정확히 추정하려는 전통적 통계 접근|
|**Objective-oriented**|실용적·정책적 목적에 맞는 유용한 추론을 강조|

[Hedonic regression - Wikipedia](https://en.wikipedia.org/wiki/Hedonic_regression)

데이터를 무작정 많이 넣는다고 좋은게 아니다, 통제된 데이터를 넣지 않으면 통계를 왜곡하게 된다.

[노벨상이 밝힌 남녀 임금격차의 진실](https://brunch.co.kr/@brazilclub/132)

linear spline regression도 중회귀 분석:
계수 ${ \beta_{1},\beta_{2} }$ 두 개로 2차원 평면을 만들기 때문인가?

도메인 지식이 없는 상태로 데이터 분석을 하는 것만큼 위험한게 없다.

조정된 결정계수: 자유도로 나눠줘서 설명변수가 정말로 제대로 역할을 하는지 판단할 수 있다. <- 지금은 잘 안 씀

KNN: 한 사람을 알려면, 그 사람의 친구를 보라.
birds of a feather flock together, 유유상종

${ y = f(x) + \varepsilon }$

$$ y - \hat{f}(x) = \overbrace{y - E(y \mid x)}^{A} + \overbrace{E(y\mid x) - f(x)}^{B} + \overbrace{f(x) - \hat{f}(x)}^{C} $$

Want ${ E[y\mid x] }$

- A: 에라 모르겠다
- B: estimation error
- C: sampling error


$$ \text{MSE} := E\left(\left( f(x) - \hat{f}(x)\right) \right) = \sigma^{2} + \mathrm{Bias}^{2} + \mathrm{Var}^{2} $$

- ${ \sigma^{2} = E(A^{2}) }$
- ${ \mathrm{Bias}^{2} = E(B^{2}) }$
- ${ \mathrm{Var}^{2} = E(C^{2}) }$

- [ ] A,B,C 쌍마다 correlation이 0인거 생각해보기

패널티를 주는 세기에 따라 모델이 결정된다. 

[Hyperparameter (Bayesian statistics) - Wikipedia](https://en.wikipedia.org/wiki/Hyperparameter_(Bayesian_statistics))

[Additive smoothing - Wikipedia](https://en.wikipedia.org/wiki/Additive_smoothing)

[Perron–Frobenius theorem - Wikipedia](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem)

[Shrinkage (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Shrinkage_(statistics))

---

## 제1장 통계학과 자료

모집단(population): 관심이 되는 집단 전체
표본(sample): 조사된 일부
모수(parameter): 모집단의 특성
통계량(statistic): 표본의 특성
추론(inference): 표분을 분석하여 모집단의 특성을 짐작

## 제10장 이항공식