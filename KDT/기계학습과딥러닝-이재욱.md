# 기계학습과 딥러닝 - 이재욱

AI를 활용하는 것은 이제 시작이다.

[Dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction)

[Feature selection](https://en.wikipedia.org/wiki/Feature_selection)

[Feature extraction](https://en.wikipedia.org/wiki/Feature_engineering)

[Garbage in, garbage out](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out)

주식에 금융AI를 도입할 수 없는 이유: 패턴이 없는데 패턴을 억지로 만들어서 예측이 틀림.

## 2025-07-29

SPD: Symmetric Positive Definite

[Cholesky decomposition - Wikipedia](https://en.wikipedia.org/wiki/Cholesky_decomposition)

${ A }$: SPD ${ \implies A=R^{T}R }$, ${ R }$ is upper-triangluar

norm ${ x : \mathbb{N} \to \mathbb{F} }$

$$ \left\lVert x \right\rVert_{1} = \sum_{n=1}^{\infty} \left\lvert x_{n} \right\rvert $$

$$ \left\lVert x \right\rVert_{2} = (\sum_{n=1}^{\infty} \left\lvert x_{n} \right\rvert^{2})^{\frac{1}{2}} $$

$$ \begin{eqnarray}
\left\lVert x \right\rVert_{\infty} & = & \inf \left\{ a \in \mathbb{R}: \#\left\{ n \in \mathbb{N} : \left\lvert x_{n} \right\rvert > a \right\} = 0 \right\} \\
& = & \inf \left\{ a \in \mathbb{R} : a \text{ is an upper bound of } \left\lvert x \right\rvert\right\} \\
& = & \sup_{n \in \mathbb{N}} \left\lvert x_{n} \right\rvert
\end{eqnarray} $$

[Triangular matrix - Wikipedia](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution)

spectral

$$ AV = V \Lambda \implies A= V\Lambda V^{T}$$

$$ \begin{bmatrix}
\lambda_{1}v_{1} & \cdots & \lambda_{n} v_{n}
\end{bmatrix} \begin{bmatrix}
v_{1}^{T} \\
\vdots \\
v_{n}^{T}
\end{bmatrix} = \lambda_{1}v_{1}v^{T}_{1} + \cdots + \lambda_{n}v_{n}v_{n}^{T} $$

[Low-rank approximation - Wikipedia](https://en.wikipedia.org/wiki/Low-rank_approximation#Basic_low-rank_approximation_problem)

[Kernel density estimation - Wikipedia](https://en.wikipedia.org/wiki/Kernel_density_estimation)

[Multicollinearity - Wikipedia](https://en.wikipedia.org/wiki/Multicollinearity)

## 2025-08-07

bias라는 용어는 언어도단. bias가 0이라고 좋은게 아님.